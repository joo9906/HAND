{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04781b4",
   "metadata": {},
   "source": [
    "### 그래픽 카드 설정 및 확인\n",
    "- 현재 kernal에서 버전 확인이 꼭 필요한 것들 확인\n",
    "- torch 버전이 2.5.1+cu121이 아닐 경우 아래의 주석 해제 후 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc8d3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook KcELECTRA_shortsentence_finetuning.ipynb to script\n",
      "[NbConvertApp] Writing 11596 bytes to KcELECTRA_shortsentence_finetuning.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script KcELECTRA_shortsentence_finetuning.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8069fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.14.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: g:\\싸피\\코드 관련\\.venv\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Name: torch\n",
      "Version: 2.5.1+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: g:\\싸피\\코드 관련\\.venv\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, peft, torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Name: transformers\n",
      "Version: 4.57.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: g:\\싸피\\코드 관련\\.venv\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Name: mlflow\n",
      "Version: 3.5.1\n",
      "Summary: MLflow is an open source platform for the complete machine learning lifecycle\n",
      "Home-page: https://mlflow.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: Copyright 2018 Databricks, Inc.  All rights reserved.\n",
      "        \n",
      "                                        Apache License\n",
      "                                   Version 2.0, January 2004\n",
      "                                http://www.apache.org/licenses/\n",
      "        \n",
      "           TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
      "        \n",
      "           1. Definitions.\n",
      "        \n",
      "              \"License\" shall mean the terms and conditions for use, reproduction,\n",
      "              and distribution as defined by Sections 1 through 9 of this document.\n",
      "        \n",
      "              \"Licensor\" shall mean the copyright owner or entity authorized by\n",
      "              the copyright owner that is granting the License.\n",
      "        \n",
      "              \"Legal Entity\" shall mean the union of the acting entity and all\n",
      "              other entities that control, are controlled by, or are under common\n",
      "              control with that entity. For the purposes of this definition,\n",
      "              \"control\" means (i) the power, direct or indirect, to cause the\n",
      "              direction or management of such entity, whether by contract or\n",
      "              otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
      "              outstanding shares, or (iii) beneficial ownership of such entity.\n",
      "        \n",
      "              \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
      "              exercising permissions granted by this License.\n",
      "        \n",
      "              \"Source\" form shall mean the preferred form for making modifications,\n",
      "              including but not limited to software source code, documentation\n",
      "              source, and configuration files.\n",
      "        \n",
      "              \"Object\" form shall mean any form resulting from mechanical\n",
      "              transformation or translation of a Source form, including but\n",
      "              not limited to compiled object code, generated documentation,\n",
      "              and conversions to other media types.\n",
      "        \n",
      "              \"Work\" shall mean the work of authorship, whether in Source or\n",
      "              Object form, made available under the License, as indicated by a\n",
      "              copyright notice that is included in or attached to the work\n",
      "              (an example is provided in the Appendix below).\n",
      "        \n",
      "              \"Derivative Works\" shall mean any work, whether in Source or Object\n",
      "              form, that is based on (or derived from) the Work and for which the\n",
      "              editorial revisions, annotations, elaborations, or other modifications\n",
      "              represent, as a whole, an original work of authorship. For the purposes\n",
      "              of this License, Derivative Works shall not include works that remain\n",
      "              separable from, or merely link (or bind by name) to the interfaces of,\n",
      "              the Work and Derivative Works thereof.\n",
      "        \n",
      "              \"Contribution\" shall mean any work of authorship, including\n",
      "              the original version of the Work and any modifications or additions\n",
      "              to that Work or Derivative Works thereof, that is intentionally\n",
      "              submitted to Licensor for inclusion in the Work by the copyright owner\n",
      "              or by an individual or Legal Entity authorized to submit on behalf of\n",
      "              the copyright owner. For the purposes of this definition, \"submitted\"\n",
      "              means any form of electronic, verbal, or written communication sent\n",
      "              to the Licensor or its representatives, including but not limited to\n",
      "              communication on electronic mailing lists, source code control systems,\n",
      "              and issue tracking systems that are managed by, or on behalf of, the\n",
      "              Licensor for the purpose of discussing and improving the Work, but\n",
      "              excluding communication that is conspicuously marked or otherwise\n",
      "              designated in writing by the copyright owner as \"Not a Contribution.\"\n",
      "        \n",
      "              \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
      "              on behalf of whom a Contribution has been received by Licensor and\n",
      "              subsequently incorporated within the Work.\n",
      "        \n",
      "           2. Grant of Copyright License. Subject to the terms and conditions of\n",
      "              this License, each Contributor hereby grants to You a perpetual,\n",
      "              worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
      "              copyright license to reproduce, prepare Derivative Works of,\n",
      "              publicly display, publicly perform, sublicense, and distribute the\n",
      "              Work and such Derivative Works in Source or Object form.\n",
      "        \n",
      "           3. Grant of Patent License. Subject to the terms and conditions of\n",
      "              this License, each Contributor hereby grants to You a perpetual,\n",
      "              worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
      "              (except as stated in this section) patent license to make, have made,\n",
      "              use, offer to sell, sell, import, and otherwise transfer the Work,\n",
      "              where such license applies only to those patent claims licensable\n",
      "              by such Contributor that are necessarily infringed by their\n",
      "              Contribution(s) alone or by combination of their Contribution(s)\n",
      "              with the Work to which such Contribution(s) was submitted. If You\n",
      "              institute patent litigation against any entity (including a\n",
      "              cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
      "              or a Contribution incorporated within the Work constitutes direct\n",
      "              or contributory patent infringement, then any patent licenses\n",
      "              granted to You under this License for that Work shall terminate\n",
      "              as of the date such litigation is filed.\n",
      "        \n",
      "           4. Redistribution. You may reproduce and distribute copies of the\n",
      "              Work or Derivative Works thereof in any medium, with or without\n",
      "              modifications, and in Source or Object form, provided that You\n",
      "              meet the following conditions:\n",
      "        \n",
      "              (a) You must give any other recipients of the Work or\n",
      "                  Derivative Works a copy of this License; and\n",
      "        \n",
      "              (b) You must cause any modified files to carry prominent notices\n",
      "                  stating that You changed the files; and\n",
      "        \n",
      "              (c) You must retain, in the Source form of any Derivative Works\n",
      "                  that You distribute, all copyright, patent, trademark, and\n",
      "                  attribution notices from the Source form of the Work,\n",
      "                  excluding those notices that do not pertain to any part of\n",
      "                  the Derivative Works; and\n",
      "        \n",
      "              (d) If the Work includes a \"NOTICE\" text file as part of its\n",
      "                  distribution, then any Derivative Works that You distribute must\n",
      "                  include a readable copy of the attribution notices contained\n",
      "                  within such NOTICE file, excluding those notices that do not\n",
      "                  pertain to any part of the Derivative Works, in at least one\n",
      "                  of the following places: within a NOTICE text file distributed\n",
      "                  as part of the Derivative Works; within the Source form or\n",
      "                  documentation, if provided along with the Derivative Works; or,\n",
      "                  within a display generated by the Derivative Works, if and\n",
      "                  wherever such third-party notices normally appear. The contents\n",
      "                  of the NOTICE file are for informational purposes only and\n",
      "                  do not modify the License. You may add Your own attribution\n",
      "                  notices within Derivative Works that You distribute, alongside\n",
      "                  or as an addendum to the NOTICE text from the Work, provided\n",
      "                  that such additional attribution notices cannot be construed\n",
      "                  as modifying the License.\n",
      "        \n",
      "              You may add Your own copyright statement to Your modifications and\n",
      "              may provide additional or different license terms and conditions\n",
      "              for use, reproduction, or distribution of Your modifications, or\n",
      "              for any such Derivative Works as a whole, provided Your use,\n",
      "              reproduction, and distribution of the Work otherwise complies with\n",
      "              the conditions stated in this License.\n",
      "        \n",
      "           5. Submission of Contributions. Unless You explicitly state otherwise,\n",
      "              any Contribution intentionally submitted for inclusion in the Work\n",
      "              by You to the Licensor shall be under the terms and conditions of\n",
      "              this License, without any additional terms or conditions.\n",
      "              Notwithstanding the above, nothing herein shall supersede or modify\n",
      "              the terms of any separate license agreement you may have executed\n",
      "              with Licensor regarding such Contributions.\n",
      "        \n",
      "           6. Trademarks. This License does not grant permission to use the trade\n",
      "              names, trademarks, service marks, or product names of the Licensor,\n",
      "              except as required for reasonable and customary use in describing the\n",
      "              origin of the Work and reproducing the content of the NOTICE file.\n",
      "        \n",
      "           7. Disclaimer of Warranty. Unless required by applicable law or\n",
      "              agreed to in writing, Licensor provides the Work (and each\n",
      "              Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
      "              WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
      "              implied, including, without limitation, any warranties or conditions\n",
      "              of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
      "              PARTICULAR PURPOSE. You are solely responsible for determining the\n",
      "              appropriateness of using or redistributing the Work and assume any\n",
      "              risks associated with Your exercise of permissions under this License.\n",
      "        \n",
      "           8. Limitation of Liability. In no event and under no legal theory,\n",
      "              whether in tort (including negligence), contract, or otherwise,\n",
      "              unless required by applicable law (such as deliberate and grossly\n",
      "              negligent acts) or agreed to in writing, shall any Contributor be\n",
      "              liable to You for damages, including any direct, indirect, special,\n",
      "              incidental, or consequential damages of any character arising as a\n",
      "              result of this License or out of the use or inability to use the\n",
      "              Work (including but not limited to damages for loss of goodwill,\n",
      "              work stoppage, computer failure or malfunction, or any and all\n",
      "              other commercial damages or losses), even if such Contributor\n",
      "              has been advised of the possibility of such damages.\n",
      "        \n",
      "           9. Accepting Warranty or Additional Liability. While redistributing\n",
      "              the Work or Derivative Works thereof, You may choose to offer,\n",
      "              and charge a fee for, acceptance of support, warranty, indemnity,\n",
      "              or other liability obligations and/or rights consistent with this\n",
      "              License. However, in accepting such obligations, You may act only\n",
      "              on Your own behalf and on Your sole responsibility, not on behalf\n",
      "              of any other Contributor, and only if You agree to indemnify,\n",
      "              defend, and hold each Contributor harmless for any liability\n",
      "              incurred by, or claims asserted against, such Contributor by reason\n",
      "              of your accepting any such warranty or additional liability.\n",
      "        \n",
      "           END OF TERMS AND CONDITIONS\n",
      "           APPENDIX: How to apply the Apache License to your work.\n",
      "        \n",
      "              To apply the Apache License to your work, attach the following\n",
      "              boilerplate notice, with the fields enclosed by brackets \"[]\"\n",
      "              replaced with your own identifying information. (Don't include\n",
      "              the brackets!)  The text should be enclosed in the appropriate\n",
      "              comment syntax for the file format. We also recommend that a\n",
      "              file or class name and description of purpose be included on the\n",
      "              same \"printed page\" as the copyright notice for easier\n",
      "              identification within third-party archives.\n",
      "        \n",
      "           Copyright [yyyy] [name of copyright owner]\n",
      "        \n",
      "           Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "           you may not use this file except in compliance with the License.\n",
      "           You may obtain a copy of the License at\n",
      "        \n",
      "               http://www.apache.org/licenses/LICENSE-2.0\n",
      "        \n",
      "           Unless required by applicable law or agreed to in writing, software\n",
      "           distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "           WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "           See the License for the specific language governing permissions and\n",
      "           limitations under the License.\n",
      "        \n",
      "Location: g:\\싸피\\코드 관련\\.venv\\lib\\site-packages\n",
      "Requires: alembic, cryptography, docker, Flask, Flask-CORS, graphene, matplotlib, mlflow-skinny, mlflow-tracing, numpy, pandas, pyarrow, scikit-learn, scipy, sqlalchemy, waitress\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tensorflow\n",
    "%pip show torch\n",
    "%pip show transformers\n",
    "%pip show mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49aa07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)       # 2.5.1\n",
    "print(torch.version.cuda)      # 12.1\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fabb2",
   "metadata": {},
   "source": [
    "토치 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b7d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\싸피\\코드 관련\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.training_args\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "print(TrainingArguments.__module__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a38c",
   "metadata": {},
   "source": [
    "CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525b52ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b6ac6",
   "metadata": {},
   "source": [
    "### 로컬에선 GPU 지정 필요없음. GPU 서버에서는 주석 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9725c23-237d-4286-8a98-98dbb371a301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df27cf1",
   "metadata": {},
   "source": [
    "- 현재 파일에서는 hugginface의 beomi/KcELECTRA-base 모델을 사용할 예정입니다.\n",
    "- 해당 모델에 관한 정보는 config 파일을 통해 관리합니다.\n",
    "- 다른 모델을 사용하기 원할 경우 config의 MODEL_NAME을 huggingface의 가이드에 따라 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ccfec",
   "metadata": {},
   "source": [
    "## 성능 향상을 위한 함수\n",
    "1. Text 정제\n",
    "- huggingface에서 개발자가 공개한 성능을 높이기 위한 데이터 전처리 과정입니다. 특수문자 및 이모지 등을 제거합니다\n",
    "- 불용어는 제거하지 않습니다. 감정 모델에서는 불용어 또한 중요한 데이터일 수 있습니다.\n",
    "2. KcELECTRA 최적화인 64 토큰으로 처리하기 위한 함수 설정\n",
    "- 논문 결과에 KcELECTRA는 토큰의 길이가 64일 경우 성능이 가장 최대로 나옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbce7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x\n",
    "\n",
    "def chunk_by_tokens(text, tokenizer, max_len=64, stride=16):\n",
    "    \"\"\"문자열을 토큰 길이 기준으로 슬라이딩 윈도우 분할\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=False,\n",
    "        return_attention_mask=False,\n",
    "        return_token_type_ids=False\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + max_len - 2, len(tokens))\n",
    "        input_ids = (\n",
    "            [tokenizer.cls_token_id]\n",
    "            + tokens[start:end]\n",
    "            + [tokenizer.sep_token_id]\n",
    "        )\n",
    "        chunk_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "        if end == len(tokens):\n",
    "            break\n",
    "        start = end - stride  # stride 만큼 겹치게 이동\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f80ef",
   "metadata": {},
   "source": [
    "### 텍스트 정제 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e455bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 오늘 선배한테 혼났어 .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"나는 오늘 선배한테 혼났어 ★.\"\n",
    "cleaned_sentence = clean(sentence)\n",
    "print(cleaned_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e62274",
   "metadata": {},
   "source": [
    "#### 감정 매핑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리 (모델의 class 순서)\n",
    "CATEGORIES = [\n",
    "    \"happy\",\n",
    "    \"embarrass\",\n",
    "    \"anger\",\n",
    "    \"unrest\",\n",
    "    \"damaged\",\n",
    "    \"sadness\",\n",
    "]\n",
    "\n",
    "# 이건 실제 csv에서 뽑아올 것.\n",
    "label_map = {\n",
    "    \"기쁨\": 0,     # happy\n",
    "    \"당황\": 1,     # embarrass\n",
    "    \"분노\": 2,     # anger\n",
    "    \"불안\": 3,     # unrest\n",
    "    \"상처\": 4,     # damaged\n",
    "    \"슬픔\": 5,     # sadness\n",
    "}\n",
    "\n",
    "NUM_LABELS = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8699216",
   "metadata": {},
   "source": [
    "## 학습 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd79d0f",
   "metadata": {},
   "source": [
    "#### 1. 모델 설정을 위한 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3a568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from config_train import ModelConfig as cf\n",
    "\n",
    "model_name = cf.MODEL_NAME\n",
    "# 전처리한 json 파일 절대 경로(상대도 가능할듯?)\n",
    "DATA_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Data\\018.감성대화\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Data\\018.감성대화\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 모델 설정. 나중에도 \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4e64c",
   "metadata": {},
   "source": [
    "#### 1-2. LoRA를 붙이기 위해 모델명 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ebe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lora_target_modules(model, patterns=None, min_hits=10):\n",
    "    \"\"\"\n",
    "    Electra 계열의 self-attention 쿼리/키/밸류/출력 dense 레이어를 자동 탐색.\n",
    "    patterns: 포함시킬 하위 모듈명 키워드 리스트 (정규식 포함 가능)\n",
    "    min_hits: 너무 적게 잡히면 경고용\n",
    "    \"\"\"\n",
    "    if patterns is None:\n",
    "        # Electra(HF)에서 흔히 보이는 명칭들\n",
    "        patterns = [r\"\\.query$\", r\"\\.key$\", r\"\\.value$\", r\"\\.dense$\"]\n",
    "\n",
    "    names = []\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            for p in patterns:\n",
    "                if re.search(p, n):\n",
    "                    names.append(n.split(\".\")[-1])  # 마지막 토큰만 추출 (PEFT는 leaf 모듈명 지정 선호)\n",
    "                    break\n",
    "\n",
    "    # leaf 모듈명만 추출했기 때문에 중복 제거\n",
    "    names = sorted(list(set(names)))\n",
    "\n",
    "    # Electra 구현에 따라 self.dense / output.dense 등 혼재 -> 최소세트 보정\n",
    "    if len(names) < 3:\n",
    "        print(\"[WARN] LoRA target modules detected too few:\", names)\n",
    "\n",
    "    print(\"[LoRA target modules]\", names)\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93577e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 설정되어있는 경우에만 사용, 현재는 이렇게 되어있음.\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=8,\n",
    "#     problem_type=\"multi_label_classification\"\n",
    "# )\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
    "import mlflow\n",
    "import os, re, torch\n",
    "\n",
    "# Electra 계열 타깃 모듈 자동 탐색\n",
    "target_modules = find_lora_target_modules(model)  # 대체로 ['query','key','value','dense'] 식으로 나옴\n",
    "\n",
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,   # 시퀀스 분류\n",
    "    r=8,                          # 랭크 (메모리/속도/성능 절충)\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=target_modules # 위에서 탐색한 모듈에만 로라 적용\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # trainable params 점검\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dbc27",
   "metadata": {},
   "source": [
    "#### 1-3. MLflow 추적을 위한 기본 세팅\n",
    "- 학습 함수의 training_args에 mlflow로 삽입은 해뒀음.\n",
    "- GPU 서버에서 돌릴 경우 서버와 로컬을 연결하는 파이프라인 설정 필요.\n",
    "- GPU 서버쪽에서 따로 열어보는건 추후에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"KcELECTRA_Short_Sentence_Finetuning\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317163a9",
   "metadata": {},
   "source": [
    "#### 2. 추론 카테고리 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb5873",
   "metadata": {},
   "source": [
    "#### 3. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, files, tokenizer, max_len=64, stride=16):\n",
    "        self.data, self.tokenizer = [], tokenizer\n",
    "        self.max_len, self.stride = max_len, stride\n",
    "\n",
    "        if isinstance(files, str):\n",
    "            files = [files]\n",
    "\n",
    "        for path in files:\n",
    "            df = pd.read_csv(path)  # 반드시 csv로 읽기\n",
    "            # 기대 컬럼: text, label, label_id\n",
    "            for _, row in df.iterrows():\n",
    "                sent = clean(str(row[\"text\"]))\n",
    "                eid  = int(row[\"label_id\"])\n",
    "                for chunk_text in chunk_by_tokens(sent, tokenizer, self.max_len, self.stride):\n",
    "                    self.data.append({\"text\": chunk_text, \"labels\": eid})\n",
    "\n",
    "    def __len__(self): return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        enc = self.tokenizer(\n",
    "            item[\"text\"], truncation=True, padding=\"max_length\",\n",
    "            max_length=self.max_len, return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(item[\"labels\"], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d5673",
   "metadata": {},
   "source": [
    "#### 4.학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18faacbb",
   "metadata": {},
   "source": [
    "training_args 부분만 LoRA 적용을 위해 수정.\n",
    "학습 데이터는 MLflow에서 받아볼 거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdf6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.57.1\n",
      "TrainingArguments module: transformers.training_args\n",
      "TrainingArguments init signature: (self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: float = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: bool = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: bool = True, label_names: Optional[list[str]] = None, load_best_model_at_end: bool = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = None, fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, parallelism_config: Optional[accelerate.parallelism_config.ParallelismConfig] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: str = 'length', report_to: Union[NoneType, str, list[str]] = None, project: str = 'huggingface', trackio_space_id: Optional[str] = 'trackio', ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: bool = False, include_num_input_tokens_seen: Union[str, bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: bool = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: bool = False, average_tokens_across_devices: bool = True) -> None\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, __version__ as tfv\n",
    "import inspect\n",
    "print(\"transformers version:\", tfv)\n",
    "print(\"TrainingArguments module:\", TrainingArguments.__module__)\n",
    "print(\"TrainingArguments init signature:\", inspect.signature(TrainingArguments.__init__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Data\\018.감성대화\\kc_electra_emotion_valid.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import EvalPrediction\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    logits = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "\n",
    "    # # multi-label 기준 metrics\n",
    "    # return {\n",
    "    #     \"accuracy\": (preds == labels).mean(),\n",
    "    #     \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "    #     \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    #     \"precision\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    #     \"recall\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    # }\n",
    "\n",
    "\n",
    "# 파일 분할 (세션 단위)\n",
    "files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(\".csv\")]\n",
    "train_files, val_files = files[0], files[1]\n",
    "\n",
    "if \"train\" in train_files == True:\n",
    "    pass\n",
    "else:\n",
    "    train_files, val_files = val_files, train_files\n",
    "\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_ds = EmotionDataset(train_files[0], tokenizer)\n",
    "val_ds = EmotionDataset(val_files[0], tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,              # 기존 경로\n",
    "    per_device_train_batch_size=cf.TRAIN_BATCH_SIZE,     \n",
    "    per_device_eval_batch_size=cf.EVAL_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=cf.LEARNING_RATE,                 # LoRA면 3e-5 ~ 5e-5 권장 (데이터 따라 튜닝)\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",         # compute_metrics에서 f1 반환한다고 가정\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    report_to=[\"mlflow\"],               # MLflow에서 report 받아서 확인할거임.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, \"best_model\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"best_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8b3b8",
   "metadata": {},
   "source": [
    "#### 5. 어댑터 설정 - 얘는 ONNX 등의 변환이 필요하면 쓰고 아니면 말거임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (1) 어댑터만 저장\n",
    "# adapter_dir = os.path.join(OUTPUT_DIR, \"lora_adapter\")\n",
    "# trainer.model.save_pretrained(adapter_dir)\n",
    "# tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "# # 추론 시: 기반 모델 + 어댑터 로드\n",
    "# # base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=8, problem_type=\"multi_label_classification\")\n",
    "# # model_lora = PeftModel.from_pretrained(base_model, adapter_dir)\n",
    "\n",
    "# # (2) 병합해서 일반 모델로 내보내기 (필요할 때)\n",
    "# merged_dir = os.path.join(OUTPUT_DIR, \"merged_model\")\n",
    "# model_lora = trainer.model\n",
    "# merged = model_lora.merge_and_unload()   # LoRA 가중치를 베이스에 병합\n",
    "# merged.save_pretrained(merged_dir)\n",
    "# tokenizer.save_pretrained(merged_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0503d1",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kcvenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
